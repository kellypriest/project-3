{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import utils\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import datasets\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import History\n",
    "\n",
    "from keras import losses\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PrimaryColor</th>\n",
       "      <th>BreedCategory</th>\n",
       "      <th>IntakeStatus</th>\n",
       "      <th>PetAgeCategory</th>\n",
       "      <th>Sex</th>\n",
       "      <th>TopBreed</th>\n",
       "      <th>BinaryOutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>PURE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>MALE</td>\n",
       "      <td>PIT BULL TERRIER</td>\n",
       "      <td>DENY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>MIX</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>BORDER COLLIE</td>\n",
       "      <td>TAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TAN</td>\n",
       "      <td>MIX</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>MALE</td>\n",
       "      <td>GOLDEN RETRIEVER</td>\n",
       "      <td>TAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>PURE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>BABY</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>LABRADOR RETRIEVER</td>\n",
       "      <td>TAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>PURE</td>\n",
       "      <td>SICK</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>MALE</td>\n",
       "      <td>PIT BULL TERRIER</td>\n",
       "      <td>DENY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PrimaryColor BreedCategory IntakeStatus PetAgeCategory     Sex  \\\n",
       "0        WHITE          PURE       NORMAL          YOUNG    MALE   \n",
       "1        BLACK           MIX       NORMAL          YOUNG  FEMALE   \n",
       "2          TAN           MIX       NORMAL          YOUNG    MALE   \n",
       "3        WHITE          PURE       NORMAL           BABY  FEMALE   \n",
       "4        BLACK          PURE         SICK          YOUNG    MALE   \n",
       "\n",
       "             TopBreed BinaryOutcome  \n",
       "0    PIT BULL TERRIER          DENY  \n",
       "1       BORDER COLLIE          TAKE  \n",
       "2    GOLDEN RETRIEVER          TAKE  \n",
       "3  LABRADOR RETRIEVER          TAKE  \n",
       "4    PIT BULL TERRIER          DENY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in csv\n",
    "df = pd.read_csv(\"LouisvilleCleanFinal.csv\").drop(['Unnamed: 0'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do a Random Forest, BinaryOutcome should be a 0 or 1.  Then only onehot encode X (see example below)\n",
    "# X = ohe.fit_transform(X)\n",
    "# X = df.drop(['BinaryOutcome', 'BinaryOutcome2'], axis=\"columns\")\n",
    "\n",
    "# df[\"BinaryOutcome2\"] = 0\n",
    "# df.loc[df[\"BinaryOutcome\"].str.contains(\"TAKE\"), \"BinaryOutcome2\"] = 1\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# # Import, initialize, fit and predict\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rf_model = RandomForestClassifier(n_estimators = 100, random_state = 42) \n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "# # Test\n",
    "# predict_y_test = rf_model.predict(X_test)\n",
    "\n",
    "# # Validate - run accuracy score\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy score: \", metrics.accuracy_score(y_test, predict_y_test))\n",
    "\n",
    "# # pickle\n",
    "# pickle.dump(rf_model, open(\"modelonehot.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To run SVM model\n",
    "# # Need to create 0/1 for BinaryOucome\n",
    "# df[\"BinaryOutcome2\"] = 0\n",
    "# df.loc[df[\"BinaryOutcome\"].str.contains(\"TAKE\"), \"BinaryOutcome2\"] = 1\n",
    "\n",
    "# # Define X and y\n",
    "# X = df.drop(['BinaryOutcome','BinaryOutcome2'], axis=\"columns\")\n",
    "# y = df['BinaryOutcome2']\n",
    "\n",
    "# # One Hot encode X\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# ohe = OneHotEncoder()\n",
    "# X = ohe.fit_transform(X).toarray()\n",
    "\n",
    "\n",
    "# # Split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X ,y, random_state=20) \n",
    "\n",
    "# # Train\n",
    "# from sklearn.svm import SVC \n",
    "# svm_model = SVC(kernel='rbf')\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# # Model Accuracy\n",
    "# print('Test Acc: %.4f' % svm_model.score(X_test, y_test))\n",
    "\n",
    "# # Save \n",
    "# pickle.dump(svm_model, open(\"SVMmodelonehot.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ohe.fit_transform(y).toarray()\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ohe.fit_transform(X).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN model - Initial model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "tensorflow.keras.__version__\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200, activation='relu', input_dim=52))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    shuffle=True,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model\n",
    "# model.save(\"NNmodelonehot.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1 - Result Normal Neural Network - Loss: 0.8209062417960498, Accuracy: 0.6994414329528809\n",
    "    * model = Sequential()\n",
    "    * model.add(Dense(units=200, activation='relu', input_dim=52))\n",
    "    * model.add(Dense(units=100, activation='relu'))\n",
    "    * model.add(Dense(units=50, activation='relu'))\n",
    "    * model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2 - Result Normal Neural Network - Loss: 0.8545986787747528, Accuracy: 0.70329350233078\n",
    "    * model = Sequential()\n",
    "    * model.add(Dense(units=200, activation='relu', input_dim=52))\n",
    "    * model.add(Dense(units=200, activation='relu'))\n",
    "    * model.add(Dense(units=200, activation='relu'))\n",
    "    * model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3 - Result Normal Neural Network - Loss: 0.820210349807754, Accuracy: 0.7028120160102844\n",
    "### (Adding more layers, not improving score)\n",
    "    * model = Sequential()\n",
    "    * model.add(Dense(units=200, activation='relu', input_dim=52))\n",
    "    * model.add(Dense(units=200, activation='relu'))\n",
    "    * model.add(Dense(units=200, activation='relu'))\n",
    "    * model.add(Dense(units=200, activation='relu'))\n",
    "    * model.add(Dense(units=200, activation='relu'))\n",
    "    * model.add(Dense(units=200, activation='relu'))\n",
    "    * model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best NETWORK WEIGHT INITIALIZATION\n",
    "    * Result: Best Accuracy for 0.6934 using {'init_mode': 'glorot_uniform'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init_mode='uniform'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, kernel_initializer=init_mode, activation='relu', input_dim=52)) \n",
    "    model.add(Dense(100, kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer=init_mode, activation='relu'))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=RMSprop(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model_CV = KerasClassifier(build_fn=create_model, epochs=epochs,batch_size=batch_size, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', \n",
    "             'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model_CV, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best OPTIMIZER\n",
    "    * Result - Best Accuracy for 0.6933 using {'optimizer': 'RMSprop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer = 'adam', init_mode='uniform'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, kernel_initializer=init_mode, activation='relu', input_dim=52)) \n",
    "    model.add(Dense(100, kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer=init_mode, activation='relu'))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model_CV = KerasClassifier(build_fn=create_model, epochs=epochs,batch_size=batch_size, verbose=1)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model_CV, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best EPOCHS and BATCH SIZE\n",
    "    * Result: Best Accuracy for 0.6944 using {'batch_size': 60, 'epochs': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer = 'adam', init_mode='uniform'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, kernel_initializer=init_mode, activation='relu', input_dim=52)) \n",
    "    model.add(Dense(100, kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer=init_mode, activation='relu'))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best Dropout Regularization\n",
    "    * Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=52, kernel_initializer='uniform', activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CV = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model_CV, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the Number of Neurons in the Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=52, kernel_initializer='uniform', activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://towardsdatascience.com/simple-guide-to-hyperparameter-tuning-in-neural-networks-3fe03dad8594\n",
    "* https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dump(rf_model, open('rf_modelTESTMarc.pkl', 'wb'))\n",
    "# new_input = [[0, 1, 0, 0, 1, 0]]\n",
    "# with open('rf_modelTESTMarc.pkl', 'rb') as file:  \n",
    "#     model = pickle.load(file)\n",
    "# model.predict(new_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_pickle('rf_modelTEST2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
